---
# kics-scan ignore
services:
  datascience-notebook:
    image: registry.gitlab.com/gitlab-data/data-image/analyst-image:v0.0.19
    volumes:
      - type: bind
        # source: ${HOME}/
        source: /home/albandrieu/
        target: /files
      - type: bind
        # source: ${HOME}/.dbt
        source: /home/albandrieu/.dbt
        target: /usr/local/snowflake_profile/
      - type: bind
        # source: ${HOME}/.ssh
        source: /home/albandrieu/.ssh
        target: /home/albanandrieu/.ssh/
    ports:
      - "8889:8888"
    environment:
      - JUPYTER_ENABLE_LAB=1
    command: start-notebook.sh --NotebookApp.notebook_dir=/files

  # See "http://127.0.0.1:8888/lab"

  # https://github.com/githubexporter/github-exporter
  github-exporter:
    tty: true
    stdin_open: true
    expose:
      - 9171
    ports:
      - 9171:9171
    image: githubexporter/github-exporter:latest
    environment:
      - REPOS=AlbanAndrieu/nabla-hooks
      - GITHUB_TOKEN=${GITHUB_TOKEN}

  # https://github.com/RichiH/openweathermap_exporter

  # See https://github.com/jokob-sk/NetAlertX/blob/main/docs/DOCKER_COMPOSE.md
  # docker compose --env-file .env --env-file .env.secrets -f  docker-compose.yml up --force-recreate  netalertx -d
  netalertx:
    container_name: netalertx
    # use the below line if you want to test the latest dev image
    # image: "ghcr.io/jokob-sk/netalertx-dev:latest"
    image: "ghcr.io/jokob-sk/netalertx:latest"
    network_mode: "host"
    # network_mode: ${NETALERTX_NETWORK_MODE:-host} # Use host networking for ARP scanning and other services

    read_only: true # Make the container filesystem read-only
    cap_drop: # Drop all capabilities for enhanced security
      - ALL
    cap_add: # Add only the necessary capabilities
      - NET_ADMIN # Required for ARP scanning
      - NET_RAW # Required for raw socket operations
      - NET_BIND_SERVICE # Required to bind to privileged ports (nbtscan)
      - CAP_NET_RAW

    restart: unless-stopped
    volumes:
      # - type: volume # Persistent Docker-managed named volume for config + database
      #   source: netalertx_data
      #   target: /data/netalertx # `/data/config` and `/data/db` live inside this mount
      #   read_only: false

      - type: bind # Bind mount for timezone consistency
        source: /etc/localtime
        target: /etc/localtime
        read_only: true

      # sudo chmod -R 777 data/
      - ./data/db:/data/db
      - ./data/config:/data/config
      - ./data/log:/tmp/log

      # - ${APP_DATA_LOCATION}/netalertx/config:/app/config
      # - ${APP_DATA_LOCATION}/netalertx/db/:/app/db/
      # # (optional) useful for debugging if you have issues setting up the container
      # - ${LOGS_LOCATION}:/app/log
      # # (API: OPTION 1) use for performance

      - type: tmpfs
        target: /app/api
      # (API: OPTION 2) use when debugging issues
      # -  local/path/api:/app/api

    # tmpfs mount consolidates writable state for a read-only container and improves performance
    # uid/gid default to the service user (NETALERTX_UID/GID, default 20211)
    # mode=1700 grants rwx------ permissions to the runtime user only
    tmpfs:
      # Comment out to retain logs between container restarts - this has a server performance impact.
      - "/tmp:uid=${NETALERTX_UID:-20211},gid=${NETALERTX_GID:-20211},mode=1700,rw,noexec,nosuid,nodev,async,noatime,nodiratime"

      # Retain logs - comment out tmpfs /tmp if you want to retain logs between container restarts
      # Please note if you remove the /tmp mount, you must create and maintain sub-folder mounts.
      # - /path/on/host/log:/tmp/log
      # - "/tmp/api:uid=${NETALERTX_UID:-20211},gid=${NETALERTX_GID:-20211},mode=1700,rw,noexec,nosuid,nodev,async,noatime,nodiratime"
      # - "/tmp/nginx:uid=${NETALERTX_UID:-20211},gid=${NETALERTX_GID:-20211},mode=1700,rw,noexec,nosuid,nodev,async,noatime,nodiratime"
      # - "/tmp/run:uid=${NETALERTX_UID:-20211},gid=${NETALERTX_GID:-20211},mode=1700,rw,noexec,nosuid,nodev,async,noatime,nodiratime"

    environment:
      # - TZ=${TZ}
      - TZ=Europe/Paris
      - LISTEN_ADDR=${LISTEN_ADDR:-0.0.0.0} # Listen for connections on all interfaces
      - PORT=${PORT:-20211} # Application port
      - GRAPHQL_PORT=${GRAPHQL_PORT:-20212} # GraphQL API port (passed into APP_CONF_OVERRIDE at runtime)
      - APP_DATA_LOCATION=/data
      # - NETALERTX_NETWORK_MODE=host
    # - NETALERTX_DEBUG=${NETALERTX_DEBUG:-0}                 # 0=kill all services and restart if any dies. 1 keeps running dead services.

    # Resource limits to prevent resource exhaustion
    mem_limit: 2048m # Maximum memory usage
    mem_reservation: 1024m # Soft memory limit
    cpu_shares: 512 # Relative CPU weight for CPU contention scenarios
    pids_limit: 512 # Limit the number of processes/threads to prevent fork bombs
    logging:
      driver: "json-file" # Use JSON file logging driver
      options:
        max-size: "10m" # Rotate log files after they reach 10MB
        max-file: "3" # Keep

  languagetool:
    image: erikvl87/languagetool
    container_name: LanguageTool
    restart: always
    ports:
      - 8010:8010 # Using default port from the image
    environment:
      - langtool_languageModel=/ngrams # OPTIONAL: Using ngrams data
      - Java_Xms=512m # OPTIONAL: Setting a minimal Java heap size of 512 mib
      - Java_Xmx=1g # OPTIONAL: Setting a maximum Java heap size of 1 Gib
    volumes:
      - ./ngrams:/ngrams

  portracker:
    image: mostafawahied/portracker:latest
    container_name: portracker
    restart: unless-stopped
    pid: "host" # Required for port detection
    # Required permissions for system ports service namespace access
    cap_add:
      - SYS_PTRACE # Linux hosts: read other PIDs' /proc entries
      - SYS_ADMIN # Docker Desktop: allow namespace access for host ports (required for MacOS)
    security_opt:
      - apparmor:unconfined # Required for system ports
    volumes:
      # Required for data persistence
      - ./portracker-data:/data
      # Required for discovering services running in Docker
      - /var/run/docker.sock:/var/run/docker.sock:ro
    ports:
      - "4999:4999"
    environment:
      # Optional: For enhanced TrueNAS features
      - TRUENAS_API_KEY=${TRUENAS_API_KEY}

  vaultwarden:
    image: vaultwarden/server:latest
    container_name: vaultwarden
    restart: unless-stopped
    environment:
      DOMAIN: "https://vaultwarden.albandrieu.com"
    volumes:
      - ./vw-data/:/data/
    ports:
      - 127.0.0.1:8000:80

  # https://localai.io/installation/docker/
  # See https://localai.io/basics/getting_started/
  # cd ~/w/follow/LocalAGI
  # docker compose -f docker-compose.nvidia.yaml up
  # localai:
  #   # image: localai/localai:latest-aio-cpu
  #   # For GPU support, use one of:
  #   image: localai/localai:latest-aio-gpu-nvidia-cuda-13
  #   # image: localai/localai:latest-aio-gpu-nvidia-cuda-12
  #   # image: localai/localai:latest-aio-gpu-nvidia-cuda-11
  #   # image: localai/localai:latest-aio-gpu-hipblas
  #   # image: localai/localai:latest-aio-gpu-intel
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8080/readyz"]
  #     interval: 1m
  #     timeout: 20m
  #     retries: 5
  #   ports:
  #     - 8080:8080
  #   environment:
  #     - DEBUG=true
  #   volumes:
  #     - ./models:/models:cached
  #   # For NVIDIA GPUs, uncomment:
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]

  dockge:
    image: louislam/dockge:1
    restart: unless-stopped
    ports:
      - 5001:5001
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /data/dockge:/app/data
      - /opt/stacks:/opt/stacks
    environment:
      # Tell Dockge where to find the stacks
      - DOCKGE_STACKS_DIR=/opt/stacks

  scrutiny-collector:
    restart: unless-stopped
    image: "ghcr.io/analogj/scrutiny:master-collector"
    cap_add:
      - SYS_RAWIO
    volumes:
      - "/run/udev:/run/udev:ro"
    environment:
      COLLECTOR_API_ENDPOINT: "http://172.17.0.24:31054/" # 'http://web:8080'
      COLLECTOR_HOST_ID: "albandrieu" # 'scrutiny-collector-hostname'
      # If true forces the collector to run on startup (cron will be started after the collector completes)
      # see: https://github.com/AnalogJ/scrutiny/blob/master/docs/TROUBLESHOOTING_DEVICE_COLLECTOR.md#collector-trigger-on-startup
      COLLECTOR_RUN_STARTUP: false
    # depends_on:
    #   web:
    #     condition: service_healthy
    devices:
      - "/dev/sda"
      - "/dev/sdb"
      - "/dev/sdc"
  # docker exec scrutiny-collector /opt/scrutiny/bin/scrutiny-collector-metrics run

  convertx:
    image: ghcr.io/c4illin/convertx
    container_name: convertx
    restart: unless-stopped
    ports:
      - "3444:3000"
    environment:
      - ACCOUNT_REGISTRATION=false
      - JWT_SECRET=${CONVERTX_JWT_SECRET} # will use randomUUID() if unset
      # - HTTP_ALLOWED=true # uncomment this if accessing it over a non-https connection
      - ALLOW_UNAUTHENTICATED=false # allows anyone to use the service without logging in, only set this to true locally
      - AUTO_DELETE_EVERY_N_HOURS=24
    volumes:
      - ./data:/app/data

  stirling-pdf:
    image: stirlingtools/stirling-pdf:latest
    container_name: stirling-pdf
    ports:
      - "8085:8080"
    volumes:
      - ./stirling-data:/configs
    restart: unless-stopped

  traefik:
    image: traefik:latest
    container_name: traefik
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    networks:
      - proxy
    ports:
      - 80:80
      - 443:443
    environment:
      - CF_API_EMAIL=${CF_API_EMAIL}
      - CF_DNS_API_TOKEN=${CF_DNS_API_TOKEN}

    command:
      - "--log.level=DEBUG"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--providers.docker.endpoint=unix:///var/run/docker.sock"
      - "--entrypoints.web.address=:80"
      - "--entrypoints.web.http.redirections.entryPoint.to=websecure"
      - "--entrypoints.web.http.redirections.entryPoint.scheme=https"
      - "--entrypoints.web.http.redirections.entrypoint.permanent=true"
      - "--entrypoints.websecure.address=:443"
      - "--entrypoints.websecure.http.tls.certResolver=cloudflare"
      - "--certificatesresolvers.cloudflare.acme.storage=acme.json"
      - "--certificatesResolvers.cloudflare.acme.email=yourcfemail@here.com"
      - "--certificatesResolvers.cloudflare.acme.dnsChallenge=true"
      - "--certificatesResolvers.cloudflare.acme.dnschallenge.provider=cloudflare"
      - "--certificatesResolvers.cloudflare.acme.dnschallenge.resolvers=1.1.1.1:53,1.0.0.1:53"
      - "--serversTransport.insecureSkipVerify=true" # Or proxmox gives an error 500 due to its own self-signed cert

    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./data/acme.json:/acme.json

include:
  # - path: pgwatch/docker/compose.postgres.yml
  # - path: pgwatch/docker/compose.pgpool.yml
  # - path: pgwatch/docker/compose.pgbouncer.yml
  # - path: pgwatch/docker/compose.grafana.yml
  - path: pgwatch/docker/compose.pgwatch.yml
  # - path: pgwatch/docker/compose.pgadmin.yml
  # - path: pgwatch/docker/compose.prometheus.yml
  - path: compose.ntopng.yml
  # - path: compose.truenas.yml
  # - path: compose.anythingllm.yml #nosec allow:gitleaks

volumes: # Persistent volume for configuration and database storage
  netalertx_data:
# # docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:lts

# cd temporal
# docker compose -f compose-postgres.yml -f compose-services.yml up --detach
#
# docker run -d \
#   --name watchtower \
#   -v /var/run/docker.sock:/var/run/docker.sock \
#   containrrr/watchtower
#
# docker run -d \
#   -p 3001:3001 \
#   louislam/uptime-kuma

networks:
  proxy:
    external: true
